{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.7 特征值分解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征值与特征向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于一个方阵 $\\mathbf A$，如果存在一个非零向量 $\\mathbf v$ 满足：\n",
    "\n",
    "$$\n",
    "\\mathbf {Av}=\\lambda\\mathbf v\n",
    "$$\n",
    "\n",
    "则称 $\\mathbf v$ 是 $\\mathbf A$ 的一个特征向量（`eigenvector`），$\\lambda$ 是 $\\mathbf A$ 的一个特征值（`eigenvalue`）。\n",
    "\n",
    "事实上，这种形式的特征向量叫做右特征向量，我们也可以定义左特征向量为：$\n",
    "\\mathbf {v^\\top A}=\\lambda\\mathbf v^\\top\n",
    "$，不过不是很常用。\n",
    "\n",
    "如果 $\\mathbf v$ 是 $\\mathbf A$ 的一个特征向量，则它的数乘 $s\\mathbf v$ 也是 $\\mathbf A$ 的一个特征向量，所以我们通常只考虑单位特征向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征值分解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果一个$n\\times n$ 矩阵 $\\bf A$ 有 $n$ 组线性无关的单位特征向量 $\\{\\mathbf v^{(1)}, \\dots, \\mathbf v^{(n)}\\}$，以及对应的特征向量 $\\lambda_1,\\dots,\\lambda_n$。将这些特征向量按列拼接成一个矩阵：$\\mathbf V = [\\mathbf v^{(1)}, \\dots, \\mathbf v^{(n)}]$，并将对应的特征值拼接成一个向量：$\\mathbf \\lambda = [\\lambda_1,\\dots,\\lambda_n]$。\n",
    "\n",
    "$\\bf A$ 的特征值分解（`eigendecomposition`）为：\n",
    "\n",
    "$$\n",
    "\\mathbf {A = V}\\text{diag}\\mathbf{(\\lambda)V}^{-1}\n",
    "$$\n",
    "\n",
    "注意：\n",
    "\n",
    "- 不是所有的矩阵都有特征值分解\n",
    "- 在某些情况下，实矩阵的特征值分解可能会得到复矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实对称矩阵的特征值分解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在机器学习中，通常我们只对实对称矩阵进行特征值分解，而实对称矩阵的特征值分解总是存在的，而且都是特征值和特征向量都是实数，而且，我们可以将其分解为：\n",
    "\n",
    "$$\n",
    "\\mathbf {A = Q \\Lambda Q}^{\\top}\n",
    "$$\n",
    "\n",
    "其中 $\\bf Q$ 是特征向量组成的正交矩阵 $\\bf \\Lambda$ 是特征值构成的对角矩阵。\n",
    "\n",
    "考虑到存在排列顺序的问题，通常我们按照特征值递减的顺序排列这些特征值和特征向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征值分解的意义 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵是奇异的等价于有一个特征值为 0。\n",
    "\n",
    "对于实对称矩阵，求特征值的问题相当于优化这个问题：\n",
    "\n",
    "$$\n",
    "f(\\mathbf x) = \\mathbf{x^\\top A x}, \\|x\\|_2=1\n",
    "$$\n",
    "\n",
    "$f(\\mathbf x)$ 的最大值为特征值的最大值，最小值为特征值的最小值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正定矩阵，负定矩阵，半正定矩阵，半负定矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 正定矩阵：所有特征值大于 0\n",
    "- 负定矩阵：所有特征值小于 0\n",
    "- 半正定矩阵：所有特征值不小于 0\n",
    "- 半负定矩阵：所有特征值不大于 0\n",
    "\n",
    "半正定和正定矩阵都满足：$\\forall x, f(\\mathbf x) = \\mathbf{x^\\top A x} \\geq 0$；正定矩阵还满足 $\\mathbf{x^\\top A x} = 0 \\Rightarrow \\mathbf{x = 0}$。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
